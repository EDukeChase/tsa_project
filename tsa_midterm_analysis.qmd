---
title: "Timerseries Analysis Midterm Analysis"
author: "E. Duke Chase"
date: today
---

# Load Packages
```{r}
#| label: setup
#| include: false

# General settings and ancillary packages
source("R/setup.R")
source("R/save_plot.R")
source("R/cache_computation.R")

# Project libraries
library(forecast)
library(tseries)

# Change default target directory and file formats for `save_plot()` function
save_plot_orig <- save_plot

make_save_plot <- function(fun, default_target = ".", default_format = "png") {
  force(fun)
  force(default_target)
  force(default_format)

  function(plot, name, format = default_format, target = default_target, ...) {
    fun(plot, name = name, format = format, target = target, ...)
  }
}

# Project defaults: output folder + png+svg
save_plot <- make_save_plot(
  fun = save_plot_orig,
  default_target = "output/figures",
  default_format = c("png", "svg")
)
```

# Data Cleaning

```{r}
#| label: load_process

# Load data
ili_raw <- read.csv(here("data", "ILINet.csv"),
                    header = TRUE,
                    skip = 1)

# Clean data
ili_clean <- ili_raw |>
  # Remove rows with missing data or no unique data
  select(
    -REGION.TYPE,         # All are "National"
    -REGION,              # All are "X"
    -X.UNWEIGHTED.ILI,    # Raw, not weighted by state size
    -contains("AGE"),     # Two of the demographic breakdowns are empty
    -ILITOTAL,            # Raw values 
    -NUM..OF.PROVIDERS,   # Raw values
    -TOTAL.PATIENTS       # Raw values
  ) |>
  
  # Standardize variable naming
  rename(year = YEAR, week = WEEK, ili_w = X..WEIGHTED.ILI) |>  
  
  # Modify to work two-year spanning flu-seasons (start week is 40)
  mutate(
    flu_season = if_else(week >= 40, year, year - 1),
    season_week = if_else(week >= 40, week - 39, week + 13),
    season_label = paste0(flu_season, "-", flu_season + 1
    )
  ) |> 
  # Remove data from the incomplete 2025-2026 flu season
  filter(flu_season < 2025)
```

One issue I'll have to deal with right off the bat is that some years have 53 weeks and some have 52. For simplicity of analysis I'm going to start off by just dropping the 53rd week from years that have it, but I will go back and do a sensitivity analysis comparing a few methods (imputing 53rd weeks for other years, averaging the 53rd week across the 52nd and 1st of next year, etc.).

```{r}
#| label: week-53-problem

# Create working dataset for seasonality check
ili_seasonal <- ili_clean |>
  # Drop 53rd week to standardize length (naive approach, revisit later)
  filter(week <= 52) |> 
  arrange(year, week)

# Create ts object
ili_ts_raw <- ts(
  ili_seasonal$ili_w,
  start = c(ili_seasonal$year[1], ili_seasonal$week[1]),
  frequency = 52
)

raw_data_plot <- plot(ili_ts_raw, 
     main = "Weighted ILI Activity", 
     ylab = "Weighted ILI %")

raw_data_plot
```

Looking at this plot, it is apparent that until about 2003, data were only collected during flu season and not over the summer months, so those flu seasons will be excluded from the analysis.

```{r}
#| label: find-zero-weeks

zero_check <- ili_seasonal |> 
  group_by(flu_season) |> 
  summarize(
    weeks_with_zero = sum(ili_w == 0, na.rm = TRUE),
    min_ili = min(ili_w, na.rm = TRUE),
    total_weeks = n()
  )

print(zero_check, n = 8)
```

Based on this output, 2002 - 2003 is the first flu season with no missing weeks, so I will discard all data before that.
Further research showed that there was sporadic collection for the summer of 2003 [@CDCExpandMonitoring], and only data on children for the summers of 2004 and 2005 [@CDCSum03], so the 2005-06 flu season will be the first included in the dataset.

```{r}
#| label: drop-pre-2005-season

# Drop data before 2005 flu season
ili_df <- ili_seasonal |> 
  filter(flu_season >= 2005) |> 
  arrange(year, week)

# Overwrite previous ts object
ili_ts <- ts(
  ili_df$ili_w,
  start = c(2005, 40),
  frequency = 52
)

clean_data_plot <- plot(ili_ts, 
     main = "Weighted ILI Activity (Cleaned)", 
     ylab = "Weighted ILI %")

clean_data_plot
```

# Exploratory Analysis
```{r}
#| label: plot_seasons
#| fig-width: 12
#| fig-height: 8

highlight_years <- c("2009-2010", "2011-2012", "2017-2018", "2019-2020", 
                     "2020-2021", "2022-2023", "2024-2025")
                     
mini_colors <- brewer.pal(7, "Dark2")
mini_tags <- paste0("(", letters[1:7],")")
                     
p_main <- ggplot(ili_df, aes(x = season_week, y = ili_w, group = flu_season)) +
  geom_line(color = "grey60", alpha = 0.5, size = 0.5) +
  labs(
    x = "Weeks into Flu Season",
    y = "Weighted ILI%"
  )

create_mini_plot <- function(i) {
  
  target_year <- highlight_years[i]
  target_color <- mini_colors[i]
  target_tag <- mini_tags[i]
  
  mini_df <- ili_df |> 
    mutate(
      is_focus = if_else(season_label == target_year, "Focus", "Background")
    ) |> 
    arrange(is_focus)
  
  ggplot(mini_df, aes(x = season_week, y = ili_w, group = flu_season)) +
    geom_line(aes(color = is_focus, size = is_focus, alpha = is_focus)) +
    
    scale_color_manual(values = c("Background" = "grey90", "Focus" = target_color)) +
    scale_size_manual(values = c("Background" = 0.3, "Focus" = 1.0)) +
    scale_alpha_manual(values = c("Background" = 0.7, "Focus" = 1.0)) +
    
    theme_void() + 
    theme(
      axis.title.x = element_text(size = 9, face = "bold", margin = margin(t = 2, b = 10)),
      panel.border = element_rect(color = "grey90", fill = NA),
      plot.tag = element_text(size = 10, face = "bold"),
      plot.tag.position = c(0.95, 0.95)
    ) +
    labs(
      x = target_year,
      tag = target_tag
    ) + 
    guides(color = "none", size = "none", alpha = "none")
}

mini_plots <- lapply(1:7, create_mini_plot)

p1 <- mini_plots[[1]]
p2 <- mini_plots[[2]]
p3 <- mini_plots[[3]]
p4 <- mini_plots[[4]]
p5 <- mini_plots[[5]]
p6 <- mini_plots[[6]]
p7 <- mini_plots[[7]]

layout_design <- "
AAAB
AAAC
AAAD
EFGH
"

flu_overview <- p_main + p1 + p2 + p3 + p4 + p5 + p6 + p7 +
  plot_layout(design = layout_design) +
  plot_annotation(
    title = "Weighted ILI %: Historical Overview & Key Anomalies",
    subtitle = "Main plot (Left) shows the full historical range.\nSubplots (Right/Bottom) isolate notable seasons."
    )

flu_overview
```




In the main figure we can see that for most flu seasons there's a peak between 13-18 weeks into the season, but there is a reasonable amount of variation in this, with one peak happening as early as 3 weeks into the flu season, and another as late as 25 weeks into the season. This is definitely more variation than would be seen just due to deleting week 53 or the slight variation in how weeks line up year to year. Interestingly, despite the wide distribution of peaks during flu season, the trough of flu season almost universally occurs around week 30.

Around the main plot I've highlighted a few flu seasons that had interesting characteristics. Subplots (a) and (c) were both heavy flu years, with (a) reflecting the H1N1 (swine flu) epidemic; swine flu had a very early start in the year compared to typical flu variants, and is also the only time I've experienced hallucinations due to fever. Subplot (b) was noteworthy due to being an incredibly mild flu season. Subplot (g) was interesting because it had two distinct peaks during the season. Lastly, subplots (d), (e) and (f) are especially indicative of the effects COVID-19 had on flu occurrence. Subplot (d) shows the flu season which included the initial spread of COVID-19, which may explain why it has three peaks instead of one like the majority of seasons have, especially since early COVID-19 strains had significant symptom overlap with influenza, and this data is related to doctor visits, not tested strains. Subplot (e) occurred during the height of non-pharmaceutical interventions intended to slow the spread (masking, social distancing, etc.)[@covid_npi], showing that there was almost no detectable flu season as a result. Subplot (f) occurred soon after the vast majority of state-level interventions had been lifted[@covid_npi], and peaked earlier in the year than typical, possibly lending credence to the idea of immune debt [@immune_debt] causing people to be more vulnerable to infection after a period of low exposure.

At this point of the exploratory analysis, it's worth splitting into the two datasets I'll be using for the analysis., since the characteristics change depending on the time period in question due to just how big of a shock event COVID-19 was to ILI% numbers. 
```{r}
#| label: split_data-by-covid

# Create updated dataframes and timeseries
# Full History [2005 - 2025]
ili_fh <- ili_df                       
ili_fh_ts <- ili_ts

# Pre-Pandemic [2005 - 2019)
ili_pp <- ili_df |>                    
  filter(flu_season < 2019)
ili_pp_ts <- ts(
  ili_pp$ili_w,
  start = c(2005, 40),
  frequency = 52
)

# Pandemic Era [2019 - 2025]
ili_pe <- ili_df |>                    
  filter(flu_season >= 2019)

ili_pe_ts <- ts(
  ili_pe$ili_w,
  start = c(2019, 40),
  frequency = 52
)
```

The full history dataset covers flu seasons 2005-06 through 2024-25 ($\text{N}_{CI} = $`r nrow(ili_fh)`, $\text{S}_{CI} = $`r n_distinct(ili_fh$season_label)`), the pre-pandemic dataset covers flu seasons 2005-06 through 2018-19 ($\text{N}_{CE} = $ `r nrow(ili_pp)`, $\text{S}_{CE} = $`r(n_distinct(ili_pp$season_label)`), and the pandemic era dataset covers flu seasons 2019-20 through 2024-25 ($\text{N}_{PE} = $`r(nrow(ili_pe)`, $\text{S}_{PE} = $`r n_distinct(ili_pe$season_label)`). The pandemic era dataset is only used to compare the pre- and post-pandemic trends, but will not be analyzed on its own.


```{r}
#| label: data-metrics-and-comparison

season_peaks_tbl <- function(df) {
  df |>
    group_by(flu_season, season_label) |>
    summarise(
      peak_ili   = max(ili_w, na.rm = TRUE),
      peak_week  = season_week[which.max(ili_w)],
      trough_ili = min(ili_w, na.rm = TRUE),
      amplitude  = peak_ili - trough_ili,
      .groups = "drop"
    )
}

peak_summary_tbl <- function(season_peaks) {
  season_peaks |>
    summarise(
      seasons           = n(),
      peak_week_median  = median(peak_week, na.rm = TRUE),
      peak_week_iqr     = IQR(peak_week, na.rm = TRUE),
      peak_week_min     = min(peak_week, na.rm = TRUE),
      peak_week_max     = max(peak_week, na.rm = TRUE),
      peak_ili_median   = median(peak_ili, na.rm = TRUE),
      peak_ili_iqr      = IQR(peak_ili, na.rm = TRUE),
      amplitude_median  = median(amplitude, na.rm = TRUE),
      amplitude_iqr     = IQR(amplitude, na.rm = TRUE),
      .groups = "drop"
    ) |>
    mutate(
      peak_week_minmax = paste0(peak_week_min, "–", peak_week_max)
    ) |>
    select(
      seasons,
      peak_week_median, peak_week_iqr, peak_week_minmax,
      peak_ili_median, peak_ili_iqr,
      amplitude_median, amplitude_iqr
    )
}

peak_long_tbl <- function(peak_summary) {
  peak_summary |>
    (\(x) enframe(as.list(x), name = "Metric", value = "Value"))() |>
    mutate(
      Metric = recode(
        Metric,
        seasons          = "Number of seasons",
        peak_week_median = "Peak week (median)",
        peak_week_iqr    = "Peak week (IQR)",
        peak_week_minmax = "Peak week (min–max)",
        peak_ili_median  = "Peak ILI% (median)",
        peak_ili_iqr     = "Peak ILI% (IQR)",
        amplitude_median = "Season amplitude (median)",
        amplitude_iqr    = "Season amplitude (IQR)",
        .default = Metric
      ),
      Value = map_chr(Value, \(v) {
        if (is.numeric(v)) sprintf("%.2f", v) else as.character(v)
      })
    )
}

fmt_p <- function(p) {
  if (is.na(p)) return("")
  if (p < 0.001) return("< 0.001")
  sprintf("%.3f", p)
}

# ---- build season-level peaks for each dataset ----
peaks_pp <- season_peaks_tbl(ili_pp)
peaks_pe <- season_peaks_tbl(ili_pe)
peaks_fh <- season_peaks_tbl(ili_fh)

# Welch Test (PP vs PE) on season-level metrics
welch_pvals <- tibble( 
  Metric = c("Peak ILI% (median)", "Season amplitude (median)", "Peak week (median)"), 
  `Welch p (CE vs CO)` = c( 
    fmt_p(t.test(peaks_pp$peak_ili, peaks_pe$peak_ili, alternative = "two.sided")$p.value),
    fmt_p(t.test(peaks_pp$amplitude, peaks_pe$amplitude, alternative = "two.sided")$p.value),
    fmt_p(t.test(peaks_pp$peak_week, peaks_pe$peak_week, alternative = "two.sided")$p.value) 
    ) 
  )

# ---- summaries into long form ----
ce_long <- peak_long_tbl(peak_summary_tbl(peaks_pp)) |> rename(`Pre-Pandemic (2005–2018)` = Value)
co_long <- peak_long_tbl(peak_summary_tbl(peaks_pe)) |> rename(`Pandemic Era (2019–2025)`       = Value)
ci_long <- peak_long_tbl(peak_summary_tbl(peaks_fh)) |> rename(`Full History (2005–2025)`= Value)

# ---- combine ----
peak_compare_tbl <- ce_long |>
  left_join(co_long, by = "Metric") |>
  left_join(welch_pvals, by = "Metric") |> # Put P-value next to the Pandemic column
  left_join(ci_long, by = "Metric") |>      # Put Full History last as reference
  mutate(
    # Optional: Replace NA p-values with empty strings for a cleaner look
    `Welch p (CE vs CO)` = replace_na(`Welch p (CE vs CO)`, "")
  ) |>
  rename(
    `Season-level summary` = Metric,
    `P-value` = `Welch p (CE vs CO)` # Shorten name since header will add context
  )

# ---- render ----
peak_compare_tbl |>
  kable(
    format = "latex",
    booktabs = TRUE,
    align = c("l", "c", "c", "c", "c"), # Center align data columns
    caption = "Season-level peak timing and intensity summaries."
  ) |>
  # CHANGE 2: Add a spanning header to explicitly link the test to the groups
  add_header_above(c(
    " " = 1, 
    "Cohort Comparison (Welch t-test)" = 3, 
    "Reference" = 1
  )) |>
  kable_styling(latex_options = c("hold_position", "scale_down"))
```

```{r}
#| label: variability-plot

make_season_profile <- function(df) {
  df |>
    group_by(season_week) |>
    summarise(
      med = median(ili_w, na.rm = TRUE),
      q25 = quantile(ili_w, 0.25, na.rm = TRUE),
      q75 = quantile(ili_w, 0.75, na.rm = TRUE),
      .groups = "drop"
    )
}

make_profile_plot <- function(df, title) {
  prof <- make_season_profile(df)

  ggplot(prof, aes(x = season_week)) +
    geom_ribbon(aes(ymin = q25, ymax = q75), alpha = 0.2) +
    geom_line(aes(y = med), linewidth = 0.8) +
    labs(
      title = title,
      subtitle = "Median ILI% with interquartile range across seasons",
      x = "Weeks into flu season",
      y = "Weighted ILI%"
    ) +
    theme_minimal()
}

p_fh <- make_profile_plot(ili_fh, "Full History (2005–2025)")
p_pp <- make_profile_plot(ili_pp, "Pre-Pandemic (2005–2018)")
p_pe <- make_profile_plot(ili_pe, "Pandemic Era (2019–2025)")

# Use shared scales
y_max <- max(
  make_season_profile(ili_fh)$q75,
  make_season_profile(ili_pp)$q75,
  make_season_profile(ili_pe)$q75,
  na.rm = TRUE
)

p_fh <- p_fh + coord_cartesian(ylim = c(0, y_max))
p_pp <- p_pp + coord_cartesian(ylim = c(0, y_max))
p_pe <- p_pe + coord_cartesian(ylim = c(0, y_max))

# --- THE FIX ---
# We create a 4-column grid.
# Row 1: Empty (#), Plot A (2 cols), Empty (#)
# Row 2: Plot B (2 cols), Plot C (2 cols)
layout <- "
#AA#
BBCC
"

peak_var_plot <- (p_fh + p_pp + p_pe) +
  plot_layout(design = layout) +
  plot_annotation(
    title = "Typical flu-season pattern and variability by week",
    subtitle = "Top: Full history (centered). Bottom: Pre- vs Post-COVID-19 comparison."
  )

peak_var_plot
```

# Analysis Prep
## Train-Test Split
```{r}
#| label: train-test-split

# Testing data with COVID-19 excluded
ili_pp_test <- ili_pp |> 
  filter(season_label == "2018-2019")
test_pp_ts <- ts(
  ili_pp_test$ili_w,
  start = c(ili_pp_test$year[1], ili_pp_test$week[1]),
  frequency = 52
)

# Training data with COVID-19 excluded
ili_pp_train <- ili_pp |> 
  filter(season_label != "2018-2019")
train_pp_ts <- ts(
  ili_pp_train$ili_w,
  start = c(ili_pp_train$year[1], ili_pp_train$week[1]),
  frequency = 52
)

# Testing data with COVID-19 included
ili_fh_test <- ili_fh |> 
  filter(season_label == "2024-2025")
test_fh_ts <- ts(
  ili_fh_test$ili_w,
  start = c(ili_fh_test$year[1], ili_fh_test$week[1]),
  frequency = 52
)

# Training data with COVID-19 included
ili_fh_train <- ili_fh |> 
  filter(season_label != "2024-2025")
train_fh_ts <- ts(
  ili_fh_train$ili_w,
  start = c(ili_fh_train$year[1], ili_fh_train$week[1]),
  frequency = 52
)
```

## Variance Stabilization
```{r}
#| label: boxcox_transform_and_plot
#| fig-width: 12
#| fig-height: 6

# Estimate lambda on training data
lambda_pp <- BoxCox.lambda(as.numeric(train_pp_ts), method = "guerrero")
lambda_fh <- BoxCox.lambda(as.numeric(train_fh_ts), method = "guerrero")

# Store the lambdas in a way that they are easily retrievable for back-transformation
bc_params <- tibble(
  dataset = c("pp", "fh"),
  lambda_hat = c(lambda_pp, lambda_fh),
  method = "guerrero"
)
saveRDS(bc_params, here("data", "boxcox_params_train_only.rds"))

# Apply BoxCox transformation to training data
train_pp_bc_ts <- BoxCox(train_pp_ts, lambda_pp)
train_fh_bc_ts <- BoxCox(train_fh_ts, lambda_fh)

# Helper functions for plots
ts_to_df <- function(x) tibble(time = as.numeric(time(x)), value = as.numeric(x))

make_ts_plot <- function(x, title, ylab) {
  ggplot(ts_to_df(x), aes(time, value)) +
    geom_line(linewidth = 0.35) +
    labs(title = title, x = NULL, y = ylab) +
    theme_minimal()
}

# Create the plots
p_pp_raw <- make_ts_plot(train_pp_ts, "Pre-Pandemic: raw", "ILI%")
p_fh_raw <- make_ts_plot(train_fh_ts, "Full History: raw", "ILI%")

p_pp_bc <- make_ts_plot(
  train_pp_bc_ts,
  bquote("Pre-Pandemic: BoxCox (" * hat(lambda) == .(sprintf("%.3f", lambda_pp)) * ")"),
  "BoxCox(ILI%)"
)
p_fh_bc <- make_ts_plot(
  train_fh_bc_ts,
  bquote("Full History: BoxCox (" * hat(lambda) == .(sprintf("%.3f", lambda_fh)) * ")"),
  "BoxCox(ILI%)"
)

data_transformation_plot <- (p_pp_raw | p_fh_raw) /
(p_pp_bc  | p_fh_bc) +
  plot_annotation(
    title = "Variance stabilization on training sets (Box–Cox)",
    subtitle = bquote(hat(lambda) * " estimated with Guerrero method")
  )

data_transformation_plot
```

As can be seen, the transformed training datasets visible in the bottom row exhibit much less variability in their peaks over the years. There is a loss of stability in terms of the lowest values, as the summer months were very constant on the original scale, but this is worth the reduction in variability of the peaks.

```{r}
#| label: stl_decomposition
#| fig-width: 12
#| fig-height: 6

stl_pp <- stl(train_pp_bc_ts, s.window = "periodic", robust = TRUE)
stl_fh <- stl(train_fh_bc_ts, s.window = "periodic", robust = TRUE)

p_stl_pp <- autoplot(stl_pp) + ggtitle("STL decomposition (PP train, Box–Cox)")
p_stl_fh <- autoplot(stl_fh) + ggtitle("STL decomposition (FH train, Box–Cox)")

decomp_plot <- (p_stl_pp | p_stl_fh) +
  plot_annotation(title = "STL decomposition on transformed training series")

decomp_plot
```

The decompositions for the two datasets both look okay, although obviously not perfect because we'd want a flat trend line and for the remainders to look more like white noise. As it is, the trend line is all over the place, but the white noise looks decent to me when you consider that we are dealing with a variable, biological process. The biggest outliers are around 2009-2010 (H1N1) and 2020-2024 (COVID-19); other than that there are small variations which clearly aren't white noise, but are pretty minimal and reflect slight shifts in when exactly the flu season starts and peaks in a given year.


```{r}
#| label: plot_acf-pacf
#| fig-asp: 1.2

acf_theme <- theme_bw() +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    axis.title = element_text(size = 11),
    axis.text  = element_text(size = 9)
  )

seasonal_highlight <- list(
  annotate("rect",
    xmin = 50, xmax = 54,
    ymin = -Inf, ymax = Inf,
    fill = brewer.pal(3, "Dark2")[1],
    alpha = 0.2
  ),
  geom_vline(
    xintercept = 52,
    color = brewer.pal(3, "Dark2")[1],
    linetype = "dashed",
    alpha = 0.6
  )
)

make_acf_pacf_set <- function(x_ts, col_label) {
  x <- as.numeric(x_ts)

  acf_st  <- ggAcf(x, lag.max = 26) +
    labs(title = paste0(col_label, ": Short-term ACF"), x = "Lag (weeks)") + acf_theme

  pacf_st <- ggPacf(x, lag.max = 26) +
    labs(title = paste0(col_label, ": Short-term PACF"), x = "Lag (weeks)") + acf_theme

  acf_lt  <- ggAcf(x, lag.max = 104) + seasonal_highlight +
    labs(title = paste0(col_label, ": Long-term ACF (2 years)"), x = "Lag (weeks)") + acf_theme

  pacf_lt <- ggPacf(x, lag.max = 104) + seasonal_highlight +
    labs(title = paste0(col_label, ": Long-term PACF (2 years)"), x = "Lag (weeks)") + acf_theme

  list(acf_st = acf_st, pacf_st = pacf_st, acf_lt = acf_lt, pacf_lt = pacf_lt)
}

# Use your transformed training series here:
pp <- make_acf_pacf_set(train_pp_bc_ts, "Pre-Pandemic")
fh <- make_acf_pacf_set(train_fh_bc_ts, "Full History")

acf_pacf_grid <-
  (pp$acf_st  | fh$acf_st) /
  (pp$pacf_st | fh$pacf_st) /
  (pp$acf_lt  | fh$acf_lt) /
  (pp$pacf_lt | fh$pacf_lt) +
  plot_annotation(
    title = "ACF/PACF diagnostics on transformed training sets",
    subtitle = "Short-term (≤26 weeks) and long-term (≤104 weeks) structure; annual seasonality highlighted near lag 52",
    caption = "Shading marks the annual seasonal cycle region (weeks 50–54)."
  )

acf_pacf_grid
```

## Pre-Modeling Checks
```{r}
#| label: premodel_checks

fmt_num <- function(x, digits = 3) {
  if (is.na(x)) return(NA_character_)
  formatC(x, format = "f", digits = digits)
}

fmt_p <- function(p) {
  if (is.na(p)) return(NA_character_)
  if (p < 0.001) "< 0.001" else fmt_num(p, 3)
}

premodel_checks <- function(x_ts, label) {
  x_ts <- as.ts(x_ts)

  # Unit root / differencing helpers
  adf_p  <- tryCatch(adf.test(x_ts, alternative = "stationary")$p.value, error = \(e) NA_real_)
  kpss_p <- tryCatch(kpss.test(x_ts, null = "Level")$p.value, error = \(e) NA_real_)

  nd_kpss <- tryCatch(ndiffs(x_ts, test = "kpss"), error = \(e) NA_integer_)
  nd_adf  <- tryCatch(ndiffs(x_ts, test = "adf"),  error = \(e) NA_integer_)
  ns_ocsb <- tryCatch(nsdiffs(x_ts, test = "ocsb"), error = \(e) NA_integer_)
  ns_seas <- tryCatch(nsdiffs(x_ts, test = "seas"), error = \(e) NA_integer_)

  tibble(
    dataset = label,
    metric = c(
      "Observations (n)",
      "Start",
      "End",
      "Suggested seasonal diffs D (OCSB)",
      "Suggested seasonal diffs D (SEAS)",
      "Suggested nonseasonal diffs d (KPSS)",
      "Suggested nonseasonal diffs d (ADF)",
      "ADF p-value (H0: unit root)",
      "KPSS p-value (H0: level stationary)"
    ),
    value = c(
      length(x_ts),
      paste(start(x_ts), collapse = ", "),
      paste(end(x_ts), collapse = ", "),
      ns_ocsb,
      ns_seas,
      nd_kpss,
      nd_adf,
      fmt_p(adf_p),
      fmt_p(kpss_p)
    )
  )
}

# ---- build a vertical-friendly table object (rows = metrics) ----
premodel_long <- bind_rows(
  premodel_checks(train_pp_bc_ts, "Pre-Pandemic (PP)"),
  premodel_checks(train_fh_bc_ts, "Full History (FH)")
)

# Option A: keep it fully vertical (never runs off page)
premodel_wide <- premodel_long |>
  pivot_wider(names_from = dataset, values_from = value) |>
  rename(`Pre-modeling check` = metric)

premodel_wide
```

Differencing diagnostics gave mixed recommendations, especially for the Full History series. We therefore treat differencing orders as candidate hyperparameters and select among them using out-of-sample forecast performance on the held-out season, alongside residual diagnostics.

# Model Building
```{r}
#| label: model_search

# Define the model configs to run
cfg <- tibble::tribble(
  ~dataset, ~d, ~D, ~tag,
  "pp",      0,  0, "pp_d0_D0",
  "pp",      0,  1, "pp_d0_D1",
  "fh",      0,  0, "fh_d0_D0",
  "fh",      0,  1, "fh_d0_D1",
  "fh",      1,  0, "fh_d1_D0",
  "fh",      1,  1, "fh_d1_D1",
  "pp",     NA, NA, "pp_auto",
  "fh",     NA, NA, "fh_auto"
)

get_series <- function(dataset) {
  if (dataset == "pp") list(train = train_pp_ts, test = test_pp_ts, lambda = lambda_pp)
  else                list(train = train_fh_ts, test = test_fh_ts, lambda = lambda_fh)
}

fit_model <- function(dataset, d, D, tag) {
  s <- get_series(dataset)

  fit <- if (is.na(d) || is.na(D)) {
    auto.arima(
      s$train,
      seasonal = TRUE,
      lambda   = s$lambda,
      biasadj  = TRUE,
      stepwise = FALSE,
      approximation = FALSE,
      max.p = 3, max.q = 3, max.P = 2, max.Q = 2
    )
  } else {
    auto.arima(
      s$train,
      d = d, D = D,
      seasonal = TRUE,
      lambda   = s$lambda,
      biasadj  = TRUE,
      stepwise = FALSE,
      approximation = FALSE,
      max.p = 3, max.q = 3, max.P = 2, max.Q = 2
    )
  }

  fc  <- forecast(fit, h = length(s$test), biasadj = TRUE)
  acc <- accuracy(fc, s$test)

  tibble::tibble(
    tag = tag,
    dataset = dataset,
    d = d, D = D,
    p = fit$arma[1], q = fit$arma[2], P = fit$arma[3], Q = fit$arma[4],
    AICc = fit$aicc,
    RMSE_test = unname(acc["Test set","RMSE"]),
    MAE_test  = unname(acc["Test set","MAE"])
  )
}

safe_fit_model <- purrr::safely(fit_model, otherwise = NULL, quiet = TRUE)

# Run multiple model options and compare to auto arima
model_search_out <- cache_computation({

  out <- cfg |>
    dplyr::mutate(
      out = furrr::future_pmap(
        .l = list(dataset, d, D, tag),
        .f = safe_fit_model,
        .options = furrr::furrr_options(seed = TRUE)
      )
    ) |>
    dplyr::mutate(
      res = purrr::map(out, "result"),
      err = purrr::map(out, "error")
    )

  results_tbl <- out |>
    dplyr::filter(purrr::map_lgl(err, is.null)) |>
    dplyr::select(res) |>
    tidyr::unnest(res) |>
    dplyr::arrange(dataset, RMSE_test)

  errors_tbl <- out |>
    dplyr::filter(!purrr::map_lgl(err, is.null)) |>
    dplyr::transmute(
      tag, dataset, d, D,
      error = purrr::map_chr(err, ~ conditionMessage(.x))
    )

  list(results_tbl = results_tbl, errors_tbl = errors_tbl)

},
cache_filename = "arima_model_search_tbl_cache.rds",
deps = list(
  cfg = cfg,
  lambda_pp = lambda_pp,
  lambda_fh = lambda_fh,
  pp_start = start(train_pp_ts), pp_end = end(train_pp_ts),
  fh_start = start(train_fh_ts), fh_end = end(train_fh_ts),
  pp_test_start = start(test_pp_ts), pp_test_end = end(test_pp_ts),
  fh_test_start = start(test_fh_ts), fh_test_end = end(test_fh_ts)
),
parallel = TRUE)

results_tbl <- model_search_out$results_tbl
errors_tbl  <- model_search_out$errors_tbl

results_tbl
errors_tbl
```


# Figures and Tables
## Data Cleaning
### Raw Data Plot
```{r}
#| label: raw_data_plot
#| eval: false
#| include: false

raw_data_plot <- plot(ili_ts_raw, 
     main = "Weighted ILI Activity", 
     ylab = "Weighted ILI %")

raw_data_plot

save_plot(raw_data_plot, "raw_data", format = "png")
```

### Clean Data Plot
```{r}
#| label: clean_data_plot
#| eval: false
#| include: false

clean_data_plot <- plot(ili_ts, 
     main = "Weighted ILI Activity (Cleaned)", 
     ylab = "Weighted ILI %")

clean_data_plot

save_plot(clean_data_plot, "clean_data", format = "png")
```

## Exploratory Analysis
### Flu Overview Plot
```{r}
#| label: flu_overview_plot
#| eval: false
#| include: false

flu_overview
save_plot(flu_overview, "flu_overview")
```

### Peak Variability Table
```{r}
#| label: peak_variability_table
#| eval: false
#| include: false

# How to import into paper and format

# peak_compare_tbl <- readRDS(here("output", "tables", "peak_compare_tbl.rds"))
#
# peak_compare_tbl |>
#   kable(
#     format = "latex",
#     booktabs = TRUE,
#     align = c("l", "c", "c", "c", "c"), # Center align data columns
#     caption = "Season-level peak timing and intensity summaries."
#   ) |>
#   # CHANGE 2: Add a spanning header to explicitly link the test to the groups
#   add_header_above(c(
#     " " = 1, 
#     "Cohort Comparison (Welch t-test)" = 3, 
#     "Reference" = 1
#   )) |>
#   kable_styling(latex_options = c("hold_position", "scale_down"))

saveRDS(peak_compare_tbl, here("output", "tables", "peak_compare_tbl.rds"))
```

### Peak Variability Plot
```{r}
#| label: peak_variability_plot
#| eval: false
#| include: false

peak_var_plot
save_plot(peak_var_plot, "peak_variability")
```

## Analysis Prep
### Data Transformation Plot
```{r}
#| label: data_transformation_plot
#| eval: false
#| include: false

data_transformation_plot
save_plot(data_transformation_plot, "data_transformation")
```

### Decomposition Plot
```{r}
#| label: decomposition_plot
#| eval: false
#| include: false

decomp_plot
save_plot(decomp_plot, "decomposition")
```


### ACF-PACF Plot
```{r}
#| label: acf-pacf_plot
#| eval: false
#| include: false

acf_pacf_grid
save_plot(acf_pacf_grid, "acf_pacf")
```

### Pre-Modeling Checks Table
```{r}
#| label: premodeling_checks_table
#| eval: false
#| include: false

# How to import into paper and format

# premodel_tbl <- readRDS(here::here("output", "tables", "premodel_checks_tbl.rds"))
# 
# premodel_tbl |>
#   kable(format = "latex", booktabs = TRUE,
#         caption = "Pre-modeling checks on Box–Cox transformed training sets.") |>
#   kable_styling(latex_options = "hold_position")

premodel_wide
saveRDS(premodel_wide, here("output", "tables", "premodel_wide_tbl.rds"))
```



## Model Building
```{r}
#| label: model_building_table
#| eval: false
#| include: false

saveRDS(results_tbl, here("output", "tables", "arima_model_selection_tbl.rds"))
if (nrow(errors_tbl) > 0) {
  saveRDS(errors_tbl, here("output", "tables", "model_selection_errors_tbl.rds"))
}
```

