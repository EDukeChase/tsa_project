---
title: "Timerseries Analysis Project - Part 1"
author: "E. Duke Chase"
date: today
---

```{r}
#| label: setup
#| include: false

# General settings and ancillary packages
source(here::here("R", "setup.R"))

# Project libraries
library(forecast)
library(tseries)
```

# Report

## Question
(a) State your research/scientific/policy question and how answering it translates to real world decisions

How far out can a timeseries model be used to predict flu-like illness occurrence with reasonable accuracy? Has this changed significantly since COVID? This question could be useful in real world decisions because it could be used in healthcare environments for predicting upcoming needs due to flu season, like staffing, stocking vaccinations, medication supplies, etc.
  


(b) Describe how time series will be used to answer it. For example: prediction, trend modeling, detection of anomalies, etc.

It will use prediction based on the time series to gauge how far out the model is useful beyond the last known data point

## Data
(a) Justify (and/or provide limitations in) how your chosen data is the correct data for your question
    
The data is a good choice because it looks at flu-like illness prevalence throughout the country, but this does come with some limitations. Mainly, that by looking at only the national level it's likely that the forecasting will be less precise than could be achieved if we refined it down to regional or state level. Additionally, it is measuring the percentage of patients that come in to doctors with influenza-like illnesses, which is generally best, but if for some reason some other disease spiked at the same time as ILIs did, but to a greater extent than ILIs, that would make the ILI measure we have go down, even though the total number of cases went up. Another issue with the data is that ILI is defined as "fever (temperature of 100°F [37.8°C] or greater) and a cough and/or a sore throat," [@ili_methods] so any increase in the prevalence of diseases with those symptoms can result in a bump. There is alternate data available that come from testing laboratories and are based on confirmed influenza cases, but there's a selection bias there since not all ILI result in a sample being sent to a lab. An additional limitation is that generally only more severe cases of ILI will result in doctor's visits, but there's not really much to be done about that other than document it.
    
(b) Discuss any data processing/cleaning/preparation steps and/or decisions related to the identification/creation of the data you used in your analysis
    
I'll have to get rid of extraneous variables that won't be used in my data, such as region (not relevant because I'm looking at the national level), or age makeup of patients. The other big issue I'll have to deal with is what to do with years that have 53 weeks instead of 52; my plan at the moment is to naively drop week 53, run my analysis, and then I can do a sensitivity analysis comparing other methods of dealing with week 53 once I have an outcome I can judge the sensitivity analysis on. Other than that, the data are pretty clean already, and I shouldn't have to create any variables to analyze.

(c) Provide a source for your data

The data comes from the U.S. Outpatient Influenza-like Illness Surveillance Network (ILINet), and was retrieved from the CDC's FluView portal [@cdc_fluview].

(d) Describe key features/properties of your time series such as size, time step units, variable being studied, etc.

There are 1467 weekly measurements spanning the time period of 1997 - 2025. The variable being studied is percentage of doctor's office visits that are related to influenza-like illnesses.
  

## Statistical Plan
(a) Provide a brief a priori analytical plan for your project. What pre-processing, visualizing, modeling steps, etc. will you conduct? (Note: what you do for item d. in the Data component section above should be described here as well)

Start out with pre-processing indicated before, basic plots of ILI percentage over time, check for stationarity, decompose the series and visualize trend, seasonality, and remaining noise. From there I'll use ACF and PACF to identify likely candidates for p, P, d, D, q, and Q, and use them for a SARIMA model, since there is usually a strong seasonal component to the occurrence of flu-like diseases. I will also estimate a Holt-Winters model to serve as a baseline comparison for the SARIMA model, and use AIC and RMSE to compare them.
    
(b) Explain how the steps in your plan build a framework for making a robust conclusion for your research question. That is, how does your plan give a complete answer to your question?

To get a good idea of the reliable forecast horizon, I'll use a train/test split to be able to see how my model performs on real world data. To determine how resilient SARIMA modeling is to shocks, I will actually have two different models: one that will be a pre-COVID19 control model that uses the years before 2019 as training data and tests on 2019, and then a complete model that uses the years before 2024 as training data and tests on 2024. 
    
For both models, I'll calculate the RMSE for each week of the forecast and comparit to a naive baseline that just assumes any given week will be the same as the same week in the previous year. Wherever the SARIMA error becomes worse than the naive error, that's the limit of my effective forecasting window. I can then compare this window in 2019 vs 2024 and quantify how much the shock of COVID19 affected model performance.

## Exploratory Data Analysis
(a) Provide any summary or other statistics/details relevant to your analytical plan and those needed to understand your final conclusions. E.g. any descriptive statistics of your time series or any feature (such as a pattern or trend) of your time series
(b) Provide and discuss at least one exploratory visualization of your time series. For example, how the visualization guided/motivated any decisions about how to use/model the data or provides insights into your question’s answer

## Statistical Analysis

(a) Estimate and interpret, in the context of your question, at least one non-ARIMA model that we used in class prior to ARIMA. For example, any of the smoothers or any of the mathematical models such as linear, exponential, polynomial, etc. Justify an related assumptions for these models (if there are any). In the Statistical Plan section you should motivate your choice in the sense of what it lets you learn about your time series related to your project goals

(b) Estimate an ARIMA model for your time series

    (i) Justify how, and that, you met any assumptions needed for an ARIMA model and explain why they must be met for ARIMA to be valid. Examples include stationarity, stable variance, etc. Examples could also include showing there is informative autocorrelation in the time series
    (ii) If there was seasonality, justify your SARIMA choices
    (iii) Justify your approach to choosing p, d, and q, and report each step/phase of this approach when applied to the data. For example, if you will systematically consider multiple models, describe this process and then provide results related to the series of candidate models. Alternatively, if you have a way to choose a single p, d, and q before estimating any models, explain how you will make this choice and why it is likely to lead to a reasonable ARIMA model. There are other approaches such as citing expert opinion or even doing something entirely new (that you can scientifically/statistically justify)
    (iv) Provide and interpret ACF and PACF plots
    (v) Justify your metric(s) for choosing a best/final model
    (vi) Provide and interpret the statistical significance of any AR or MA coefficients in your final estimated model
    (vii) Analyze the residuals to validate your final ARIMA model. Explain why each check you are performing with the residuals is necessary

## Final Model and Conclusions
(a) Provide an equation for your final estimated model and explain all parameters and variables in this equation
(b) Use the model and/or its statistical output to answer your research question. Provide both a statistical answer (e.g. the calculated prediction interval was _____) and a practical answer (e.g. implications of your conclusion/answer/inference in the real world domain of your question)
(c) Discuss the strengths and limitations of ARIMA for your data/question. Note: the final project for our class is an extension of this project where you will compare your ARIMA model to other models from other approaches; thus, this could be a reasonable place to start motivating properties you would ideally like in different models


# Data pre-processing and cleaning

```{r}
#| label: load_process

# Load data
ili_raw <- read.csv(here("data", "ILINet.csv"),
                    header = TRUE,
                    skip = 1)

# Clean data
ili_clean <- ili_raw |>
  # Remove rows with missing data or no unique data
  select(
    -REGION.TYPE,         # All are "National"
    -REGION,              # All are "X"
    -X.UNWEIGHTED.ILI,    # Raw, not weighted by state size
    -contains("AGE"),     # Two of the demographic breakdowns are empty
    -ILITOTAL,            # Raw values 
    -NUM..OF.PROVIDERS,   # Raw values
    -TOTAL.PATIENTS       # Raw values
  ) |>
  
  # Standardize variable naming
  rename(year = YEAR, week = WEEK, ili_w = X..WEIGHTED.ILI) |>  
  
  # Modify to work two-year spanning flu-seasons (start week is 40)
  mutate(
    flu_season = if_else(week >= 40, year, year - 1),
    season_week = if_else(week >= 40, week - 39, week + 13),
    season_label = paste0(flu_season, "-", flu_season + 1
    )
  )
```

One issue I'll have to deal with right off the bat is that some years have 53 weeks and some have 52. For simplicity of analysis I'm going to start off by just dropping the 53rd week from years that have it, but I will go back and do a sensitivity analysis comparing a few methods (imputing 53rd weeks for other years, averaging the 53rd week across the 52nd and 1st of next year, etc.).

```{r}
#| label: week-53-problem

# Create working dataset for seasonality check
ili_seasonal <- ili_clean |>
  # Drop 53rd week to standardize length (naive approach, revisit later)
  filter(week <= 52) |> 
  arrange(year, week)

# Create ts object
ili_ts <- ts(
  ili_seasonal$ili_w,
  start = c(ili_seasonal$year[1], ili_seasonal$week[1]),
  frequency = 52
)

plot(ili_ts, 
     main = "Weighted ILI Activity", 
     ylab = "Weighted ILI %")
```

Looking at this plot, it is apparent that until about 2003, data were only collected during flu season and not over the summer months, so those flu seasons will be excluded from the analysis.

```{r}
#| label: find-zero-weeks

zero_check <- ili_seasonal |> 
  group_by(flu_season) |> 
  summarize(
    weeks_with_zero = sum(ili_w == 0, na.rm = TRUE),
    min_ili = min(ili_w, na.rm = TRUE),
    total_weeks = n()
  )

print(zero_check, n = 8)
```

Based on this output, 2002 - 2003 is the first flu season with no missing weeks, so I will discard all years before that.

```{r}
#| label: drop-pre-2002-season

# Drop data before 2003
ili_df <- ili_seasonal |> 
  filter(flu_season >= 2002) |> 
  arrange(year, week)

# Overwrite previous ts object
ili_ts <- ts(
  ili_df$ili_w,
  start = c(2002, 40),
  frequency = 52
)

plot(ili_ts, 
     main = "Weighted ILI Activity (Cleaned)", 
     ylab = "Weighted ILI %")
```

# Exploratory Analysis
```{r}
#| label: seasonal-plots
#| fig-width: 12
#| fig-height: 8

highlight_years <- c("2003-2004", "2009-2010", "2017-2018", "2019-2020", 
                     "2020-2021", "2022-2023", "2024-2025")
                     
mini_colors <- brewer.pal(7, "Dark2")
mini_tags <- paste0("(", letters[1:7],")")
                     
p_main <- ggplot(ili_df, aes(x = season_week, y = ili_w, group = flu_season)) +
  geom_line(color = "grey60", alpha = 0.5, size = 0.5) +
  labs(
    x = "Weeks into Flu Season",
    y = "Weighted ILI%"
  )

create_mini_plot <- function(i) {
  
  target_year <- highlight_years[i]
  target_color <- mini_colors[i]
  target_tag <- mini_tags[i]
  
  mini_df <- ili_df |> 
    mutate(
      is_focus = if_else(season_label == target_year, "Focus", "Background")
    ) |> 
    arrange(is_focus)
  
  ggplot(mini_df, aes(x = season_week, y = ili_w, group = flu_season)) +
    geom_line(aes(color = is_focus, size = is_focus, alpha = is_focus)) +
    
    scale_color_manual(values = c("Background" = "grey90", "Focus" = target_color)) +
    scale_size_manual(values = c("Background" = 0.3, "Focus" = 1.0)) +
    scale_alpha_manual(values = c("Background" = 0.7, "Focus" = 1.0)) +
    
    theme_void() + 
    theme(
      axis.title.x = element_text(size = 9, face = "bold", margin = margin(t = 2, b = 10)),
      panel.border = element_rect(color = "grey90", fill = NA),
      plot.tag = element_text(size = 10, face = "bold"),
      plot.tag.position = c(0.95, 0.95)
    ) +
    labs(
      x = target_year,
      tag = target_tag
    ) + 
    guides(color = "none", size = "none", alpha = "none")
}

mini_plots <- lapply(1:7, create_mini_plot)

p1 <- mini_plots[[1]]
p2 <- mini_plots[[2]]
p3 <- mini_plots[[3]]
p4 <- mini_plots[[4]]
p5 <- mini_plots[[5]]
p6 <- mini_plots[[6]]
p7 <- mini_plots[[7]]

layout_design <- "
AAAB
AAAC
AAAD
EFGH
"

p_main + p1 + p2 + p3 + p4 + p5 + p6 + p7 +
  plot_layout(design = layout_design) +
  plot_annotation(
    title = "Weighted ILI %: Historical Overview & Key Anomalies",
    subtitle = "Main plot (Left) shows the full historical range. Subplots (Right/Bottom) isolate notable seasons."
    )
```




In the main figure we can see that for most flu seasons there's a peak between 13-18 weeks into the season, but there is a reasonable amount of variation in this, with one peak happening as early as 3 weeks into the flu season, and another as late as 25 weeks into the season. This is definitely more variation than would be seen just due to deleting week 53 or the slight variation in how weeks line up year to year. Interestingly, despite the wide distribution of peaks during flu season, the trough of flu season almost universally occurs around week 30.

Around the main plot I've highlighted a few flu seasons that had interesting characteristics. Subplots (a), (b) and (c) were all heavy flu years, with (b) reflecting the H1N1 (swine flu) epidemic; swine flu had a very early start in the year compared to typical flu variants, and is also the only time I've experienced hallucinations due to fever. Subplots (d) and (g) were interesting because they have two or more peaks during the season. Lastly, subplots (e) and (f) are especially indicative of the effects COVID19 had on flu occurrence. Sublot (e) occurred during the height of non-pharmaceutical interventions intended to slow the spread (masking, social distancing, etc.)[@covid_npi], showing that there was almost no detectable flu season as a result. Subplot (f) occurred soon after the vast majority of state-level interventions had been lifted[@covid_npi], and peaked significantly earlier in the year than typical, possibly lending credence to the idea of immune debt [@immune_debt] causing people to be more vulnerable to infection after a period of low exposure.

```{r}
adf.test(ili_ts, alternative = "stationary")
kpss.test(ili_ts, null = "Level")
```
The Augmented Dickey-Fuller test indicates that the data are stationary, but the KPSS test indicates that there is a trend. This isn't super surprising since flu rates are known to be very seasonal

```{r}
#| label: acf-pacf
#| fig-asp: 0.8

acf_theme <- theme_bw() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )

seasonal_highlight <- list(
  # Shade weeks 50-54
  annotate("rect",
    xmin = 50, xmax = 54, 
    ymin = -Inf, ymax = Inf,
    fill = brewer.pal(3, "Dark2")[1], 
    alpha = 0.2
  ),
  # Vertical line at week 52
  geom_vline(
    xintercept = 52, 
    color = brewer.pal(3, "Dark2")[1], 
    linetype = "dashed", 
    alpha = 0.6
    )
)

acf_st <- ggAcf(as.numeric(ili_ts), lag.max = 26) +
  labs(title = "Short-Term ACF", x = "Lag (weeks)") + acf_theme
pacf_st <- ggPacf(as.numeric(ili_ts), lag.max = 26) +
  labs(title = "Short-Term PACF", x = "Lag (weeks)") + acf_theme
acf_lt <- ggAcf(as.numeric(ili_ts), lag.max = 104) + seasonal_highlight +
  labs(title = "Seasonal ACF (2 Years)", x = "Lag (weeks)") + acf_theme
pacf_lt <- ggPacf(as.numeric(ili_ts), lag.max = 104) + seasonal_highlight +
  labs(title = "Seasonal PACF (2 Years)", x = "Lag (weeks)") + acf_theme

(acf_st + pacf_st) / (acf_lt + pacf_lt) + 
  plot_annotation(
    caption = "Highlight roughly indicates the annual seasonal cycle (Weeks 50-54)"
    )
```

Definitely don't have exponential decay in the ACF plot, but the PACF has very good exponential decay, falling off immediately with a few random significant spikes which are to be expected just due to the number of lags being shown. Looking at the long-term plots, the sinusoidal appearance of the ACF is strongly indicative of a seasonal trend, and the long term PACF plot reinforces this, with lags near week 52 generally being significant.


```{r}
#| label: decomposition

ili_decomp <- stl(ili_ts, s.window = "periodic")
plot(ili_decomp, main = "STL Decomposition of Weighted ILI %")
```

Basic STL (season-trend-loess) decomposition. Seasonality is pretty clear, but the trend line is very much not linear, and doesn't look stationary, and based on the remainders it looks like there's at least some amount of cyclical or seasonal trend which isn't being accounted for on top of the few spikes that correlate to significant events: 2003 - 2004 was a particularly heavy flu year that started pretty early, 2009 was swine flu, 2020-2023 reflect the impacts of COVID19; also, after the 2021 - 2022 the definition for ILI no longer includes "without a known cause other than influenza", which would reduce the number of ILI since ruling out COVID19 would be a possibility. 

Because this isn't super clear I'm going to try a

```{r}
ili_log_ts <- log(ili_ts)

ili_log_decomp <- stl(ili_log_ts, s.window = "periodic")
plot(ili_log_decomp, main = "STL Decomposition of log(Weighted ILI %)")

ili_flexible_decomp <- stl(ili_log_ts, s.window = 11)

plot(ili_flexible_decomp, main = "STL Decomposition (Evolving Seasonality)")
```

```{r}
# Find the optimal Box-Cox parameter
lambda_opt <- BoxCox.lambda(ili_ts)
print(paste("Optimal Lambda:", lambda_opt))

# Apply the optimal transformation
ili_boxcox_ts <- BoxCox(ili_ts, lambda_opt)

# Decompose the optimally transformed data
ili_opt_decomp <- stl(ili_boxcox_ts, s.window = "periodic") # Combine with flexible window
plot(ili_opt_decomp, main = paste("STL with Lambda =", round(lambda_opt, 2)))
```

```{r}
# Compare different windows side-by-side
# Note: Using the Box-Cox transformed data is still best
par(mfrow=c(2,2)) # 2x2 grid

# 1. Rapid Evolution (Window = 7)
plot(stl(ili_boxcox_ts, s.window=7)$time.series[, "remainder"], 
     main="Remainder (s.window = 7)", ylab="")

# 2. Moderate Evolution (Window = 13) - Your current choice
plot(stl(ili_boxcox_ts, s.window=13)$time.series[, "remainder"], 
     main="Remainder (s.window = 13)", ylab="")

# 3. Slow Evolution (Window = 21)
plot(stl(ili_boxcox_ts, s.window=21)$time.series[, "remainder"], 
     main="Remainder (s.window = 21)", ylab="")

# 4. Fixed (Periodic)
plot(stl(ili_boxcox_ts, s.window="periodic")$time.series[, "remainder"], 
     main="Remainder (Periodic)", ylab="")

par(mfrow=c(1,1)) # Reset plot area
```

```{r}
# Define the windows you want to test
# Must be odd numbers or "periodic"
windows_to_test <- c(7, 13, 21, 51, 101, "periodic")

# Create a storage frame
tuning_results <- data.frame(
  window = as.character(windows_to_test),
  ACF_Lag52 = NA,
  Remainder_Var = NA
)

# Loop through and test
for(i in 1:length(windows_to_test)) {
  
  # 1. Decompose (Handle "periodic" vs numeric)
  win <- windows_to_test[i]
  if(win != "periodic") win <- as.numeric(win)
  
  decomp <- stl(ili_boxcox_ts, s.window = win)
  remainder <- decomp$time.series[, "remainder"]
  
  # 2. Calculate Metric A: Seasonality in the Noise (ACF at lag 52)
  # Note: frequency is 52, so lag 1.0 in 'acf' output = 52 weeks
  acf_val <- acf(remainder, lag.max = 52, plot = FALSE)$acf[53] 
  # Index 53 corresponds to lag 52 (Index 1 is lag 0)
  
  # 3. Calculate Metric B: Variance of the Noise
  var_val <- var(remainder)
  
  # Store
  tuning_results$ACF_Lag52[i] <- acf_val
  tuning_results$Remainder_Var[i] <- var_val
}

# View the results sorted by Window size
print(tuning_results)
```

```{r}
library(ggplot2)
library(tidyr)

# 1. Generate a sequence of ODD integers
# We'll go from 7 to 51. Going higher usually just flatlines.
windows_to_test <- seq(7, 51, by = 2)

# 2. Create storage
tuning_results <- data.frame(
  window = windows_to_test,
  ACF_Lag52 = NA,
  Remainder_Var = NA
)

# 3. Loop
for(i in 1:length(windows_to_test)) {
  win <- windows_to_test[i]
  
  # Decompose (assuming ili_boxcox_ts is your best data version)
  decomp <- stl(ili_boxcox_ts, s.window = win)
  remainder <- decomp$time.series[, "remainder"]
  
  # Metric A: Seasonality in Noise
  # Index 53 corresponds to lag 52 (1 year)
  tuning_results$ACF_Lag52[i] <- acf(remainder, lag.max = 52, plot = FALSE)$acf[53]
  
  # Metric B: Variance of Noise
  tuning_results$Remainder_Var[i] <- var(remainder)
}

# 4. Reshape for easy plotting with ggplot
results_long <- tuning_results %>%
  pivot_longer(cols = c("ACF_Lag52", "Remainder_Var"), 
               names_to = "Metric", 
               values_to = "Value")

# 5. Plot the "Tuning Curve"
ggplot(results_long, aes(x = window, y = Value, color = Metric)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  facet_wrap(~Metric, scales = "free_y", ncol = 1) +
  # Add a reference line for the "Perfect" ACF (0)
  geom_hline(data = subset(results_long, Metric == "ACF_Lag52"), 
             aes(yintercept = 0), linetype = "dashed") +
  # Highlight your candidate (13)
  geom_vline(xintercept = 13, linetype = "dotted", color = "black") +
  scale_x_continuous(breaks = seq(7, 51, by = 4)) +
  theme_minimal() +
  labs(
    title = "STL Tuning: Finding the Optimal s.window",
    subtitle = "Goal: ACF near 0 (unbiased) and low Variance (good fit)",
    x = "Seasonal Window (s.window)",
    y = "Value"
  )
```

# Model Prep
```{r}
#| label: train-test-split

# Subset the training and test datasets
# 2002-2003 through 2023-2024 seasons
train_df <- ili_df |> 
  filter(flu_season < 2024) |> 
  arrange(year, week)

# Just the 2024-2025 season
test_df <- ili_df |> 
  filter(flu_season == 2024) |> 
  arrange(year, week)

# Convert to time series objects
train_ts <- ts(
  train_df$ili_w,
  start = c(train_df$year[1], train_df$week[1]),
  frequency = 52
)

test_ts <- ts(
  test_df$ili_w,
  start = c(test_df$year[1], test_df$week[1]),
  frequency = 52
)
```

# Seasonal Naive Model



# Holt-Winters Model

```{r}
#| label: hw-model

hw_model <- HoltWinters(train_ts, seasonal = "additive")
hw_forecast <- forecast(hw_model, h = length(test_ts))

autoplot(hw_forecast, include = 102) +
  autolayer(test_ts, series = "Actual (2024-2025)", size = 1) +
  scale_color_manual(values = c("Actual (2024-2025)" = "black", "Predicted" = "#0072B2")) +
labs(
  title = "Holt-Winters Forecast Validation",
  subtitle = "Training: 2002-2023 | Test: 2024-2025 Flu Season",
  y = "Weighted ILI%",
  x = "Year"
)
```


# SARIMA Model



# References
::: {#refs}
:::