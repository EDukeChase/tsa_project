---
title: "Timerseries Analysis Midterm Outline"
author: "E. Duke Chase"
date: today
---

# Outline
## Question
(a) State your research/scientific/policy question and how answering it translates to real world decisions

\color{blue}
How far out can we forecast weekly flu-like illness occurrence with acceptable accuracy? Has this horizon changed significantly since COVID? This question could be useful in real world decisions because it could be used in healthcare environments for predicting upcoming needs due to flu season, like staffing, stocking vaccinations, medication supplies, etc.
\color{black}

(b) Describe how time series will be used to answer it. For example: prediction, trend modeling, detection of anomalies, etc.

\color{blue}
For each forecast horizon $h \in \{1,2,\ldots,52\}$, I compute cumulative mean absolute error: $$\mathrm{CMAE}_{m}(h) = \frac{1}{h}\sum_{k=1}^{h}\left|y_{t+k}-\hat{y}^{(m)}_{t+k\mid t}\right|,$$
where $t$ is the final week in the training set and $\hat{y}^{(m)}_{t+k\mid t}$ is the $k$-step-ahead forecast from model $m$.

I define the effective forecast horizon as$$h^* = \max\{h : \mathrm{CMAE}_{m}(h) < \mathrm{CMAE}_{\text{snaive}}(h)\},$$ where $\mathrm{CMAE}_{\text{snaive}}(h)$ is computed analogously for a seasonal naive baseline. If the SARIMA never beats the seasonally naive model, I'll denote that with $h* = 0$
\color{black}

## Data
(a) Justify (and/or provide limitations in) how your chosen data is the correct data for your question

\color{blue}
The data is a good choice because it looks at flu-like illness prevalence throughout the country, but this does come with some limitations. Mainly, that by looking at only the national level it's likely that the forecasting will be less precise than could be achieved if we refined it down to regional or state level. Additionally, it is measuring the percentage of patients that come in to doctors with influenza-like illnesses, which is generally best, but if for some reason some other disease spiked at the same time as ILIs did, but to a greater extent than ILIs, that would make the ILI measure we have go down, even though the total number of cases went up. Another issue with the data is that ILI is defined as "fever (temperature of 100°F [37.8°C] or greater) and a cough and/or a sore throat," [@ili_methods] so any increase in the prevalence of diseases with those symptoms can result in a bump. There is alternate data available that come from testing laboratories and are based on confirmed influenza cases, but there's a selection bias there since not all ILI result in a sample being sent to a lab. An additional limitation is that generally only more severe cases of ILI will result in doctor's visits, but there's not really much to be done about that other than document it.
\color{black}

(b) Discuss any data processing/cleaning/preparation steps and/or decisions related to the identification/creation of the data you used in your analysis

\color{blue}    
I'll have to get rid of extraneous variables that won't be used in my data, such as region (not relevant because I'm looking at the national level), or age makeup of patients. The other big issue I'll have to deal with is what to do with years that have 53 weeks instead of 52; my plan at the moment is to naively drop week 53, run my analysis, and then I can do a sensitivity analysis comparing other methods of dealing with week 53 once I have an outcome I can judge the sensitivity analysis on. Other than that, the data are pretty clean already, and I shouldn't have to create any variables to analyze.

As a note: 5 of the 28 years of data had 53 weeks
\color{black}

(c) Provide a source for your data

\color{blue}
The data comes from the U.S. Outpatient Influenza-like Illness Surveillance Network (ILINet), and was retrieved from the CDC's FluView portal [@cdc_fluview].
\color{black}

(d) Describe key features/properties of your time series such as size, time step units, variable being studied, etc.

\color{blue}
There are 1467 weekly measurements spanning the time period of 1997 - 2025. The variable being studied is percentage of doctor's office visits that are related to influenza-like illnesses.
\color{black}

## Statistical Plan
(a) Provide a brief a priori analytical plan for your project. What pre-processing, visualizing, modeling steps, etc. will you conduct? (Note: what you do for item d. in the Data component section above should be described here as well)

\color{blue}
Start out with pre-processing indicated before, basic plots of ILI percentage over time, check for stationarity, decompose the series and visualize trend, seasonality, and remaining noise. From there I'll use ACF and PACF to identify likely candidates for p, P, d, D, q, and Q, and use them for a SARIMA model, since there is usually a strong seasonal component to the occurrence of flu-like diseases. I will also estimate a Holt-Winters model to serve as a baseline comparison for the SARIMA model, and use AIC and RMSE to compare them.
\color{black}

(b) Explain how the steps in your plan build a framework for making a robust conclusion for your research question. That is, how does your plan give a complete answer to your question?

\color{blue}
To get a good idea of the reliable forecast horizon, I'll use a train/test split to be able to see how my model performs on real world data. To determine how resilient SARIMA modeling is to shocks, I will actually have two different models: one that will be a pre-COVID19 control model that uses the years before 2019 as training data and tests on 2019, and then a complete model that uses the years before 2024 as training data and tests on 2024. 
    
For both models, I'll calculate the RMSE for each week of the forecast and comparit to a naive baseline that just assumes any given week will be the same as the same week in the previous year. Wherever the SARIMA error becomes worse than the naive error, that's the limit of my effective forecasting window. I can then compare this window in 2019 vs 2024 and quantify how much the shock of COVID19 affected model performance.
\color{black}

## Exploratory Data Analysis
(a) Provide any summary or other statistics/details relevant to your analytical plan and those needed to understand your final conclusions. E.g. any descriptive statistics of your time series or any feature (such as a pattern or trend) of your time series

\color{blue}
The dataset did not include any data during the flu off-season (weeks 21-39 of the year) until 2003, when partial monitoring began [@CDCExpandMonitoring], and off-season reporting slowly increased until it became normal in the 2005-2006 flue season, at which point data for children and adults began routinely being collected year round [@CDCSum03]. Data included 5 years with 53 weeks instead of 52, so the 53rd weeks were dropped from the analysis (somewhat common solution to the problem based on what I've read), which obviously biases the data and introduces some mismatch in terms of year-over-year alignment. For the analysis I began the series at the onset of the 2002-03 flu season (week 40 of 2002), and modeled it as a weekly time series with a frequency of 52 weeks. There is strong annual seasonality with a relatively consistent trend of peaking in severity around week 55 (15 weeks into the flu season) although there is substantial variability in the timing and intensity of the peaks. There is a much more consistent trend of falling off to very low levels around 1-2% around week 18 (30 weeks into the flu season). Several seasons show significant abnormalities in either intensity or timing of peak flu load.

Stationarity diagnostics are somewhat mixed, with an ADF test suggesting stationarity (p = 0.01), a KPSS test for stationarity with trend failing to reject stationarity (p = 0.10), while a KPSS test for level stationarity provided evidence against stationarity (p = 0.01). Visual inspection reveals a strong seasonality to the data, and variable amplitude in peaks suggests transforming the data to try and minimize the effect of this variance on the analysis before beginning to look at decomposition and ARIMA diagnostics.
\color{black}

(b) Provide and discuss at least one exploratory visualization of your time series. For example, how the visualization guided/motivated any decisions about how to use/model the data or provides insights into your question’s answer

\color{blue}
In the main figure we can see that for most flu seasons there's a peak between 13-18 weeks into the season, but there is a reasonable amount of variation in this, with one peak happening as early as 3 weeks into the flu season, and another as late as 25 weeks into the season. This is definitely more variation than would be seen just due to deleting week 53 or the slight variation in how weeks line up year to year. Interestingly, despite the wide distribution of peaks during flu season, the trough of flu season almost universally occurs around week 30.

Around the main plot I've highlighted a few flu seasons that had interesting characteristics. Subplots (a), (b) and (c) were all heavy flu years, with (b) reflecting the H1N1 (swine flu) epidemic; swine flu had a very early start in the year compared to typical flu variants, and is also the only time I've experienced hallucinations due to fever. Subplot (g) was interesting because it had two peaks during the season. Lastly, subplots (d), (e) and (f) are especially indicative of the effects COVID19 had on flu occurrence. Subplot (d) shows the flu season which included the initial spread of COVID19, which is quite likely why it has three peaks instead of one like the majority of seasons have, especially since early COVID19 strains had significant symptom overlap with influenza, and this data is related to doctor visits, not tested strains. Subplot (e) occurred during the height of non-pharmaceutical interventions intended to slow the spread (masking, social distancing, etc.)[@covid_npi], showing that there was almost no detectable flu season as a result. Subplot (f) occurred soon after the vast majority of state-level interventions had been lifted[@covid_npi], and peaked significantly earlier in the year than typical, possibly lending credence to the idea of immune debt [@immune_debt] causing people to be more vulnerable to infection after a period of low exposure.
\color{black}

## Statistical Analysis

(a) Estimate and interpret, in the context of your question, at least one non-ARIMA model that we used in class prior to ARIMA. For example, any of the smoothers or any of the mathematical models such as linear, exponential, polynomial, etc. Justify an related assumptions for these models (if there are any). In the Statistical Plan section you should motivate your choice in the sense of what it lets you learn about your time series related to your project goals

\color{blue}

\color{black}

(b) Estimate an ARIMA model for your time series

    (i) Justify how, and that, you met any assumptions needed for an ARIMA model and explain why they must be met for ARIMA to be valid. Examples include stationarity, stable variance, etc. Examples could also include showing there is informative autocorrelation in the time series

\color{blue}

\color{black}
    (ii) If there was seasonality, justify your SARIMA choices

\color{blue}

\color{black}
    (iii) Justify your approach to choosing p, d, and q, and report each step/phase of this approach when applied to the data. For example, if you will systematically consider multiple models, describe this process and then provide results related to the series of candidate models. Alternatively, if you have a way to choose a single p, d, and q before estimating any models, explain how you will make this choice and why it is likely to lead to a reasonable ARIMA model. There are other approaches such as citing expert opinion or even doing something entirely new (that you can scientifically/statistically justify)

\color{blue}

\color{black}
    (iv) Provide and interpret ACF and PACF plots

\color{blue}

\color{black}
    (v) Justify your metric(s) for choosing a best/final model

\color{blue}

\color{black}
    (vi) Provide and interpret the statistical significance of any AR or MA coefficients in your final estimated model

\color{blue}

\color{black}
    (vii) Analyze the residuals to validate your final ARIMA model. Explain why each check you are performing with the residuals is necessary

\color{blue}

\color{black}

## Final Model and Conclusions
(a) Provide an equation for your final estimated model and explain all parameters and variables in this equation
(b) Use the model and/or its statistical output to answer your research question. Provide both a statistical answer (e.g. the calculated prediction interval was _____) and a practical answer (e.g. implications of your conclusion/answer/inference in the real world domain of your question)
(c) Discuss the strengths and limitations of ARIMA for your data/question. Note: the final project for our class is an extension of this project where you will compare your ARIMA model to other models from other approaches; thus, this could be a reasonable place to start motivating properties you would ideally like in different models

## General Guidelines/Requirements
(a) Provide the above in a logically ordered, professional (polished and error free), and
easily readable format
(b) It is possible that not every project will need every step in every component and/or
the order of components may change. Use your best judgement (and/or ask me) to
include any of the above components (or even ones I didn’t mention) relevant to your
project
(c) Do not just cut and paste R output and add a few sentences around the output
(d) Provide a bibliography section for any sources used. This could be related to the data
or any source you used (except you don’t have to site me) when conducting the
project work
(e) Submit a single pdf version of your report (please double space)
(f) Provide me both your data and a reasonably clean/commented version of your R code

# References
::: {#refs}
:::